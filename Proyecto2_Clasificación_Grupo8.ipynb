{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aoUAYSLhAy_BhdIauJfrg-GrFexK6m3N",
      "authorship_tag": "ABX9TyN0Yqw2KjcPRNIJxmmYsQvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebasurtos/Machine-Learning/blob/main/Proyecto2_Clasificaci%C3%B3n_Grupo8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Participantes: (Colocar el % de participación)\n",
        "\n",
        "1 Jorge Palacios 35%\n",
        "\n",
        "2.Eder Basurto 35%\n",
        "\n",
        "3 Rodolfo Morocho 30%"
      ],
      "metadata": {
        "id": "F9yDcHDVDzcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proyecto #2 (Clasificación):\n",
        "\n",
        "El objetivo de este proyecto es clasificar a los pacientes como con COVID-19, utilizando únicamente el sonido de su tos. Para ello, su grupo puede usar bibliotecas para obtener el mejor vector de características que represente el sonido de la tos. El conjunto de datos contiene las señales sonoras de pacientes con y sin COVID-19. El conjunto de datos se crea a partir de muestras recopiladas de COSWARA y Virufy, que son altamente fiables. Hay 1207 toses de personas con resultado negativo y 150 de personas con resultado positivo de COVID-19"
      ],
      "metadata": {
        "id": "ObCnO-fsDzJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actividades:\n",
        "\n",
        "Utilice el conjunto de datos \"Toses\" y aplique los siguientes algoritmos de clasificación: Regresión logística, SVM, Árboles de decisión y KNN.\n",
        "Implemente (puntuación sobre 20) o utilice bibliotecas (puntuación sobre 15) para clasificar el conjunto de datos utilizando SVM, KNN y Árboles de decisión.\n",
        "Realice el proceso de entrenamiento utilizando validación cruzada de K-fold y Bootstrap para estimar el error.\n",
        "En una tabla, presente los valores de Precisión, Recall y Puntuación F1 para cada prueba de hiperparámetro en cada modelo.\n",
        "Finalmente, concluya qué modelos ofrecen los mejores resultados"
      ],
      "metadata": {
        "id": "aHO52rGqD7Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa as lb\n",
        "import os\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Configuración de directorios\n",
        "base_dir = '/content/drive/MyDrive/ML_Data/tos/cleaned_data'  # Asegúrate de que esta ruta es correcta\n",
        "\n",
        "# --- Extracción de características mejorada ---\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        y, sr = lb.load(file_path, sr=None)  # sr=None para mantener la frecuencia original\n",
        "\n",
        "        # Extracción de características con parámetros consistentes\n",
        "        mfccs = lb.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "        chroma = lb.feature.chroma_stft(y=y, sr=sr)\n",
        "        mel = lb.feature.melspectrogram(y=y, sr=sr)\n",
        "        contrast = lb.feature.spectral_contrast(y=y, sr=sr)\n",
        "        tonnetz = lb.feature.tonnetz(y=lb.effects.harmonic(y), sr=sr)\n",
        "\n",
        "        # Calculamos estadísticas para cada característica\n",
        "        features = np.concatenate([\n",
        "            np.mean(mfccs, axis=1), np.std(mfccs, axis=1),\n",
        "            np.mean(chroma, axis=1), np.std(chroma, axis=1),\n",
        "            np.mean(mel, axis=1), np.std(mel, axis=1),\n",
        "            np.mean(contrast, axis=1), np.std(contrast, axis=1),\n",
        "            np.mean(tonnetz, axis=1), np.std(tonnetz, axis=1)\n",
        "        ])\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando archivo {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Procesamiento de datos\n",
        "def load_data(base_dir):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for label, class_name in enumerate(['Negative', 'Positive']):\n",
        "        class_dir = os.path.join(base_dir, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Advertencia: Directorio no encontrado - {class_dir}\")\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.wav'):\n",
        "                file_path = os.path.join(class_dir, filename)\n",
        "                extracted_features = extract_features(file_path)\n",
        "                if extracted_features is not None:\n",
        "                    features.append(extracted_features)\n",
        "                    labels.append(label)\n",
        "\n",
        "    if not features:\n",
        "        raise ValueError(\"No se encontraron archivos de audio válidos. Verifique las rutas y extensiones.\")\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "try:\n",
        "    X, y = load_data(base_dir)\n",
        "\n",
        "    # --- Preprocesamiento ---\n",
        "    # Dividir datos antes de cualquier transformación para evitar data leakage\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # --- Modelos con pipeline de escalado ---\n",
        "    models = {\n",
        "        'Logistic Regression': make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),\n",
        "        'SVM': make_pipeline(StandardScaler(), SVC()),\n",
        "        'Decision Tree': DecisionTreeClassifier(),\n",
        "        'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # --- Validación Cruzada K-Fold ---\n",
        "    print(\"Realizando Validación Cruzada K-Fold...\")\n",
        "    n_splits_kfold = 5\n",
        "    kf = KFold(n_splits=n_splits_kfold, shuffle=True, random_state=42)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        metrics = {\n",
        "            'Accuracy': [],\n",
        "            'Precision': [],\n",
        "            'Recall': [],\n",
        "            'F1-Score': []\n",
        "        }\n",
        "\n",
        "        for train_index, val_index in kf.split(X_train):\n",
        "            X_train_kf, X_val_kf = X_train[train_index], X_train[val_index]\n",
        "            y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
        "\n",
        "            model.fit(X_train_kf, y_train_kf)\n",
        "            y_pred_kf = model.predict(X_val_kf)\n",
        "\n",
        "            metrics['Accuracy'].append(accuracy_score(y_val_kf, y_pred_kf))\n",
        "            metrics['Precision'].append(precision_score(y_val_kf, y_pred_kf))\n",
        "            metrics['Recall'].append(recall_score(y_val_kf, y_pred_kf))\n",
        "            metrics['F1-Score'].append(f1_score(y_val_kf, y_pred_kf))\n",
        "\n",
        "        results[f'{name}_KFold'] = {\n",
        "            'Accuracy': np.mean(metrics['Accuracy']),\n",
        "            'Precision': np.mean(metrics['Precision']),\n",
        "            'Recall': np.mean(metrics['Recall']),\n",
        "            'F1-Score': np.mean(metrics['F1-Score'])\n",
        "        }\n",
        "        print(f\"{name} - KFold completado\")\n",
        "\n",
        "    # --- Bootstrap ---\n",
        "    print(\"\\nRealizando Bootstrap...\")\n",
        "    n_iterations_bootstrap = 100\n",
        "    bootstrap_scores = {name: {'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': []}\n",
        "                       for name in models.keys()}\n",
        "\n",
        "    for i in range(n_iterations_bootstrap):\n",
        "        X_train_bs, y_train_bs = resample(X_train, y_train, replace=True, random_state=i)\n",
        "\n",
        "        for name, model in models.items():\n",
        "            model.fit(X_train_bs, y_train_bs)\n",
        "            y_pred_bs = model.predict(X_test)\n",
        "\n",
        "            bootstrap_scores[name]['Accuracy'].append(accuracy_score(y_test, y_pred_bs))\n",
        "            bootstrap_scores[name]['Precision'].append(precision_score(y_test, y_pred_bs))\n",
        "            bootstrap_scores[name]['Recall'].append(recall_score(y_test, y_pred_bs))\n",
        "            bootstrap_scores[name]['F1-Score'].append(f1_score(y_test, y_pred_bs))\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Iteración Bootstrap {i + 1}/{n_iterations_bootstrap} completada\")\n",
        "\n",
        "    for name in models.keys():\n",
        "        results[f'{name}_Bootstrap'] = {\n",
        "            'Accuracy': np.mean(bootstrap_scores[name]['Accuracy']),\n",
        "            'Precision': np.mean(bootstrap_scores[name]['Precision']),\n",
        "            'Recall': np.mean(bootstrap_scores[name]['Recall']),\n",
        "            'F1-Score': np.mean(bootstrap_scores[name]['F1-Score'])\n",
        "        }\n",
        "\n",
        "    # --- Presentación de Resultados ---\n",
        "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "    print(\"\\nResultados de Clasificación:\")\n",
        "    print(results_df.round(4))\n",
        "\n",
        "    # --- Análisis de Resultados ---\n",
        "    print(\"\\nAnálisis Final:\")\n",
        "\n",
        "    # Mejor modelo según K-Fold\n",
        "    kfold_results = results_df[results_df.index.str.endswith('KFold')]\n",
        "    best_kfold = kfold_results['F1-Score'].idxmax()\n",
        "    print(f\"\\nMejor modelo en Validación Cruzada (F1-Score): {best_kfold}\")\n",
        "    print(kfold_results.loc[best_kfold])\n",
        "\n",
        "    # Mejor modelo según Bootstrap\n",
        "    bootstrap_results = results_df[results_df.index.str.endswith('Bootstrap')]\n",
        "    best_bootstrap = bootstrap_results['F1-Score'].idxmax()\n",
        "    print(f\"\\nMejor modelo en Bootstrap (F1-Score): {best_bootstrap}\")\n",
        "    print(bootstrap_results.loc[best_bootstrap])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError en la ejecución: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1RIPU672-b5S",
        "outputId": "7dbe0ae3-5f2b-4fba-e277-1c41d7535b6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=800\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
            "  return pitch_tuning(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=928\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=992\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=768\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=640\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=960\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=832\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=896\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1128578731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# --- Preprocesamiento ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-1128578731.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mextracted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mextracted_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-1128578731.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcontrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtonnetz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtonnetz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mharmonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Calculamos estadísticas para cada característica\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/effects.py\u001b[0m in \u001b[0;36mharmonic\u001b[0;34m(y, kernel_size, power, mask, margin, n_fft, hop_length, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Remove percussives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     stft_harm = decompose.hpss(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mstft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     )[0]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/decompose.py\u001b[0m in \u001b[0;36mhpss\u001b[0;34m(S, kernel_size, power, mask, margin)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Compute median filters. Pre-allocation here preserves memory layout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mharm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     \u001b[0mharm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mharm_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mperc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mmedian_filter\u001b[0;34m(input, size, footprint, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \"\"\"\n\u001b[0;32m-> 1684\u001b[0;31m     return _rank_filter(input, 0, size, footprint, output, mode, cval,\n\u001b[0m\u001b[1;32m   1685\u001b[0m                         origin, 'median', axes=axes)\n\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36m_rank_filter\u001b[0;34m(input, rank, size, footprint, output, mode, cval, origin, operation, axes)\u001b[0m\n\u001b[1;32m   1578\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m             \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfootprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemp_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}